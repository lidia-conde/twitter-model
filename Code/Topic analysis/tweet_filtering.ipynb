{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from functools import reduce\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIR = './'\n",
    "os.chdir(PATH_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Data/Dataset 2022/'\n",
    "PATH_FILE_XLSX = 'tweets.xlsx'\n",
    "\n",
    "df_tweets = pd.read_excel(PATH+PATH_FILE_XLSX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>entities</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593016536024769024</td>\n",
       "      <td>1529463808053616896</td>\n",
       "      <td>This place is pretty dead... By which I mean, ...</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1593016536016749056</td>\n",
       "      <td>1553398174584377088</td>\n",
       "      <td>@Mark_Baden And this is just the beginning...ðŸ¥¶ðŸ˜³</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>1.592998e+18</td>\n",
       "      <td>474414285.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1593016536016429056</td>\n",
       "      <td>1465584077751397888</td>\n",
       "      <td>RT @CantStopLion: ðŸ“ºðŸ”Š Magoon Devin Nunes is the...</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1593006457330761984</td>\n",
       "      <td>1018632078269616000</td>\n",
       "      <td>ðŸ“ºðŸ”Š Magoon Devin Nunes is the face of the Derp ...</td>\n",
       "      <td>Wed Nov 16 22:21:50 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593016536016749056</td>\n",
       "      <td>100084136</td>\n",
       "      <td>RT @youhearbiggirls: How do I sum up the best ...</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id              user_id  \\\n",
       "0  1593016536024769024  1529463808053616896   \n",
       "1  1593016536016749056  1553398174584377088   \n",
       "2  1593016536016429056  1465584077751397888   \n",
       "3  1593006457330761984  1018632078269616000   \n",
       "4  1593016536016749056            100084136   \n",
       "\n",
       "                                                text  \\\n",
       "0  This place is pretty dead... By which I mean, ...   \n",
       "1    @Mark_Baden And this is just the beginning...ðŸ¥¶ðŸ˜³   \n",
       "2  RT @CantStopLion: ðŸ“ºðŸ”Š Magoon Devin Nunes is the...   \n",
       "3  ðŸ“ºðŸ”Š Magoon Devin Nunes is the face of the Derp ...   \n",
       "4  RT @youhearbiggirls: How do I sum up the best ...   \n",
       "\n",
       "                       created_at  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  Wed Nov 16 23:01:53 +0000 2022                    NaN                  NaN   \n",
       "1  Wed Nov 16 23:01:53 +0000 2022           1.592998e+18          474414285.0   \n",
       "2  Wed Nov 16 23:01:53 +0000 2022                    NaN                  NaN   \n",
       "3  Wed Nov 16 22:21:50 +0000 2022                    NaN                  NaN   \n",
       "4  Wed Nov 16 23:01:53 +0000 2022                    NaN                  NaN   \n",
       "\n",
       "   quote_count  reply_count  retweet_count  favorite_count  \\\n",
       "0            0            0              0               0   \n",
       "1            0            0              0               0   \n",
       "2            0            0              0               0   \n",
       "3            0            0              2               2   \n",
       "4            0            0              0               0   \n",
       "\n",
       "                                            entities   type  \n",
       "0  {'hashtags': [], 'urls': [], 'user_mentions': ...  tweet  \n",
       "1  {'hashtags': [], 'urls': [], 'user_mentions': ...  tweet  \n",
       "2  {'hashtags': [], 'urls': [{'url': 'https://t.c...     RT  \n",
       "3  {'hashtags': [], 'urls': [{'url': 'https://t.c...  tweet  \n",
       "4  {'hashtags': [], 'urls': [], 'user_mentions': ...     RT  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_tweets = df_tweets[df_tweets['type'] != 'RT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(text):\n",
    "    return re.findall('(#+[a-zA-Z0-9(_)]{2,})', text)\n",
    "\n",
    "def get_entities(text):\n",
    "    parsed_tweet = p.parse(text)\n",
    "    chosen_entities = [parsed_tweet.hashtags, parsed_tweet.emojis, parsed_tweet.smileys, parsed_tweet.numbers, parsed_tweet.urls]\n",
    "    chosen_names = ['hashtags', 'emojis', 'smileys', 'numbers', 'urls']\n",
    "    dict_ent = {}\n",
    "\n",
    "    for entity,name in zip(chosen_entities, chosen_names):\n",
    "        dict_ent[name] = []\n",
    "        if (entity != None):\n",
    "            for i in range(len(entity)):\n",
    "                dict_ent[name].append(entity[i].match)\n",
    "\n",
    "    return dict_ent\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    tweet = re.sub(\"[Ã Ã¡Ã¢Ã£Ã¤Ã¥]\",\"a\", text)\n",
    "    tweet = re.sub(\"[Ã¨Ã©ÃªÃ«]\",\"e\", tweet)\n",
    "    tweet = re.sub(\"[Ã¬Ã­Ã®Ã¯]\",\"i\", tweet)\n",
    "    tweet = re.sub(\"[Ã²Ã³Ã´Ã¶]\",\"o\", tweet)\n",
    "    tweet = re.sub(\"[Ã¹ÃºÃ»Ã¼]\",\"u\", tweet)\n",
    "    return tweet\n",
    "\n",
    "contractions = { \n",
    "\"ain't\": \"is not\",\n",
    "#\"aren't\": \"are not\",\n",
    "\"can't\": \"can not\",\n",
    "\"can't've\": \"can not have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "#\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "#\"didn't\": \"did not\",\n",
    "#\"doesn't\": \"does not\",\n",
    "#\"don't\": \"do not\",\n",
    "#\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "#\"hasn't\": \"has not\",\n",
    "#\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "#\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "#\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "#\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "#\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "#\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "#\"she's\": \"she is\",\n",
    "#\"should've\": \"should have\",\n",
    "#\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "#\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "#\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "#\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "#\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "#\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "#\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "#\"you're\": \"you are\",\n",
    "#\"you've\": \"you have\"\n",
    "\"u\": \"you\",\n",
    "\"u're\": \"you are\",\n",
    "\"ure\": \"you are\",\n",
    "\"u r\": \"you are\",\n",
    "\"ur\": \"your\"\n",
    "}\n",
    "\n",
    "def expand_contractions(text):\n",
    "    for key,val in contractions.items():\n",
    "        text = re.sub(\"\\\\b\"+key+\"\\\\b\", val, text)\n",
    "    return text\n",
    "\n",
    "StopWords = stopwords.words(\"english\")\n",
    "\n",
    "def clean_tweet(text):\n",
    "    tweet = re.sub('\\n', ' ', text) # remove line jumps\n",
    "    tweet = re.sub(\"\\u2026\", \" \", tweet) # remove triple dots\n",
    "    tweet = p.clean(tweet)\n",
    "    tweet = re.sub(\"[0-9]\", \" \", tweet) # remove numbers\n",
    "    tweet = re.sub('\\&amp;', 'and', tweet) # replace ampersands\n",
    "    tweet = re.sub('['+punctuation + ']+', ' ', tweet) # remove punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub(r'([A-Za-z])\\1{2,}', r'\\1', tweet) # remove repeated characters\n",
    "    tweet = tweet.lower() # make lower case\n",
    "    tweet = remove_diacritics(tweet)\n",
    "    tweet = expand_contractions(tweet)\n",
    "    tweet = ' '.join([word for word in tweet.split() if word not in StopWords])\n",
    "    return tweet\n",
    "\n",
    "def stem_tweet(text):\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    return reduce(lambda x, y: x + \" \" + ps.stem(y), words, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in tweet 4649\n",
      "Text:  0\n"
     ]
    }
   ],
   "source": [
    "filtered_text = pd.Series(dtype=str)\n",
    "tokenized_text = pd.Series(dtype=str)\n",
    "stemmed_text = pd.Series(dtype=str)\n",
    "hashtags = pd.Series()\n",
    "emojis = pd.Series()\n",
    "smileys = pd.Series()\n",
    "numbers = pd.Series()\n",
    "urls = pd.Series()\n",
    "punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~â€¢@'\n",
    "\n",
    "for idx,text in OG_tweets['text'].items():\n",
    "    try:\n",
    "        tweet = clean_tweet(text)\n",
    "\n",
    "        filtered_text[idx] = tweet\n",
    "        stemmed_text[idx] = stem_tweet(tweet)\n",
    "\n",
    "        tokenized_text[idx] = p.tokenize(text)\n",
    "\n",
    "        entities = get_entities(text)\n",
    "\n",
    "        hashtags[idx] = entities['hashtags']\n",
    "        emojis[idx] = entities['emojis']\n",
    "        smileys[idx] = entities['smileys']\n",
    "        numbers[idx] = entities['numbers']\n",
    "        urls[idx] = entities['urls']\n",
    "    except:\n",
    "        print(\"Error in tweet\",idx)\n",
    "        print(\"Text: \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets = df_tweets.drop(['filtered_text', 'tokenized_text', 'stemmed_text', 'hashtags', 'emojis', 'smileys', 'numbers', 'urls'], axis=1)\n",
    "\n",
    "df_tweets['filtered_text'] = filtered_text\n",
    "df_tweets['tokenized_text'] = tokenized_text\n",
    "df_tweets['stemmed_text'] = stemmed_text\n",
    "df_tweets['hashtags'] = hashtags\n",
    "df_tweets['emojis'] = emojis\n",
    "df_tweets['smileys'] = smileys\n",
    "df_tweets['numbers'] = numbers\n",
    "df_tweets['urls'] = urls\n",
    "\n",
    "df_tweets = df_tweets.fillna({'hashtags':'[]', 'emojis':'[]', 'smileys':'[]', 'numbers':'[]', 'urls':'[]'}).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>entities</th>\n",
       "      <th>type</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emojis</th>\n",
       "      <th>smileys</th>\n",
       "      <th>numbers</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593016536024769024</td>\n",
       "      <td>1529463808053616896</td>\n",
       "      <td>This place is pretty dead... By which I mean, ...</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>place pretty dead mean nothing kill</td>\n",
       "      <td>This place is pretty dead... By which I mean, ...</td>\n",
       "      <td>place pretti dead mean noth kill</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1593016536016749056</td>\n",
       "      <td>1553398174584377088</td>\n",
       "      <td>@Mark_Baden And this is just the beginning...ðŸ¥¶ðŸ˜³</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>1.592998e+18</td>\n",
       "      <td>474414285.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>beginning</td>\n",
       "      <td>$MENTION$ And this is just the beginning...$EM...</td>\n",
       "      <td>begin</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ðŸ˜³]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1593016536016429056</td>\n",
       "      <td>1465584077751397888</td>\n",
       "      <td>RT @CantStopLion: ðŸ“ºðŸ”Š Magoon Devin Nunes is the...</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>RT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1593006457330761984</td>\n",
       "      <td>1018632078269616000</td>\n",
       "      <td>ðŸ“ºðŸ”Š Magoon Devin Nunes is the face of the Derp ...</td>\n",
       "      <td>Wed Nov 16 22:21:50 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>magoon devin nunes face derp state</td>\n",
       "      <td>$EMOJI$$EMOJI$ Magoon Devin Nunes is the face ...</td>\n",
       "      <td>magoon devin nune face derp state</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ðŸ“º, ðŸ”Š]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/8lQozzZJxH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593016536016749056</td>\n",
       "      <td>100084136</td>\n",
       "      <td>RT @youhearbiggirls: How do I sum up the best ...</td>\n",
       "      <td>Wed Nov 16 23:01:53 +0000 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>RT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id              user_id  \\\n",
       "0  1593016536024769024  1529463808053616896   \n",
       "1  1593016536016749056  1553398174584377088   \n",
       "2  1593016536016429056  1465584077751397888   \n",
       "3  1593006457330761984  1018632078269616000   \n",
       "4  1593016536016749056            100084136   \n",
       "\n",
       "                                                text  \\\n",
       "0  This place is pretty dead... By which I mean, ...   \n",
       "1    @Mark_Baden And this is just the beginning...ðŸ¥¶ðŸ˜³   \n",
       "2  RT @CantStopLion: ðŸ“ºðŸ”Š Magoon Devin Nunes is the...   \n",
       "3  ðŸ“ºðŸ”Š Magoon Devin Nunes is the face of the Derp ...   \n",
       "4  RT @youhearbiggirls: How do I sum up the best ...   \n",
       "\n",
       "                       created_at  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  Wed Nov 16 23:01:53 +0000 2022                    NaN                  NaN   \n",
       "1  Wed Nov 16 23:01:53 +0000 2022           1.592998e+18          474414285.0   \n",
       "2  Wed Nov 16 23:01:53 +0000 2022                    NaN                  NaN   \n",
       "3  Wed Nov 16 22:21:50 +0000 2022                    NaN                  NaN   \n",
       "4  Wed Nov 16 23:01:53 +0000 2022                    NaN                  NaN   \n",
       "\n",
       "   quote_count  reply_count  retweet_count  favorite_count  \\\n",
       "0            0            0              0               0   \n",
       "1            0            0              0               0   \n",
       "2            0            0              0               0   \n",
       "3            0            0              2               2   \n",
       "4            0            0              0               0   \n",
       "\n",
       "                                            entities   type  \\\n",
       "0  {'hashtags': [], 'urls': [], 'user_mentions': ...  tweet   \n",
       "1  {'hashtags': [], 'urls': [], 'user_mentions': ...  tweet   \n",
       "2  {'hashtags': [], 'urls': [{'url': 'https://t.c...     RT   \n",
       "3  {'hashtags': [], 'urls': [{'url': 'https://t.c...  tweet   \n",
       "4  {'hashtags': [], 'urls': [], 'user_mentions': ...     RT   \n",
       "\n",
       "                         filtered_text  \\\n",
       "0  place pretty dead mean nothing kill   \n",
       "1                            beginning   \n",
       "2                                  NaN   \n",
       "3   magoon devin nunes face derp state   \n",
       "4                                  NaN   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  This place is pretty dead... By which I mean, ...   \n",
       "1  $MENTION$ And this is just the beginning...$EM...   \n",
       "2                                                NaN   \n",
       "3  $EMOJI$$EMOJI$ Magoon Devin Nunes is the face ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                         stemmed_text hashtags  emojis smileys numbers  \\\n",
       "0    place pretti dead mean noth kill       []      []      []      []   \n",
       "1                               begin       []     [ðŸ˜³]      []      []   \n",
       "2                                 NaN       []      []      []      []   \n",
       "3   magoon devin nune face derp state       []  [ðŸ“º, ðŸ”Š]      []      []   \n",
       "4                                 NaN       []      []      []      []   \n",
       "\n",
       "                        urls  \n",
       "0                         []  \n",
       "1                         []  \n",
       "2                         []  \n",
       "3  [https://t.co/8lQozzZJxH]  \n",
       "4                         []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Data/Dataset 2022/'\n",
    "FILE_NAME = 'filtered_tweets.xlsx'\n",
    "\n",
    "df_tweets.to_excel(PATH+FILE_NAME+'.xlsx', engine='xlsxwriter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
